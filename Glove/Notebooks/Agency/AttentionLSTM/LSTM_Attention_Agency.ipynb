{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Attention_Agency.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9uag8ljF07Og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "!pip install torchtext\n",
        "!pip install spacy && python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Riv1NfxbnfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "labeled_train = \"https://raw.githubusercontent.com/kj2013/claff-happydb/master/data/TRAIN/labeled_10k.csv\"\n",
        "unlabeled_train = \"https://raw.githubusercontent.com/kj2013/claff-happydb/master/data/TRAIN/unlabeled_70k.csv\"\n",
        "unlabeled_test = \"https://raw.githubusercontent.com/kj2013/claff-happydb/master/data/TEST/unlabeled_17k.csv\"\n",
        "labeled_data = pd.read_table(labeled_train,sep=',',index_col=False, error_bad_lines=False) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3spTQAmnuHz2",
        "colab_type": "code",
        "outputId": "e3f7489b-8045-4ec6-a5d9-b67231c52970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "cell_type": "code",
      "source": [
        "labeled_data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hmid</th>\n",
              "      <th>moment</th>\n",
              "      <th>concepts</th>\n",
              "      <th>agency</th>\n",
              "      <th>social</th>\n",
              "      <th>age</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>married</th>\n",
              "      <th>parenthood</th>\n",
              "      <th>reflection</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27674</td>\n",
              "      <td>I was happy when my son got 90% marks in his e...</td>\n",
              "      <td>education|family</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>29.0</td>\n",
              "      <td>IND</td>\n",
              "      <td>m</td>\n",
              "      <td>married</td>\n",
              "      <td>y</td>\n",
              "      <td>24h</td>\n",
              "      <td>half_a_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27685</td>\n",
              "      <td>went to movies with my friends it was fun</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>29.0</td>\n",
              "      <td>IND</td>\n",
              "      <td>m</td>\n",
              "      <td>single</td>\n",
              "      <td>y</td>\n",
              "      <td>24h</td>\n",
              "      <td>half_a_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27691</td>\n",
              "      <td>A hot kiss with my girl friend last night made...</td>\n",
              "      <td>romance</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>25.0</td>\n",
              "      <td>IND</td>\n",
              "      <td>m</td>\n",
              "      <td>married</td>\n",
              "      <td>y</td>\n",
              "      <td>24h</td>\n",
              "      <td>at_least_one_hour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27701</td>\n",
              "      <td>My son woke me up to a fantastic breakfast of ...</td>\n",
              "      <td>family|food</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>79</td>\n",
              "      <td>USA</td>\n",
              "      <td>f</td>\n",
              "      <td>widowed</td>\n",
              "      <td>y</td>\n",
              "      <td>24h</td>\n",
              "      <td>all_day_im_still_feeling_it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27712</td>\n",
              "      <td>My older daughter keeps patting my younger dau...</td>\n",
              "      <td>family</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>30</td>\n",
              "      <td>USA</td>\n",
              "      <td>f</td>\n",
              "      <td>married</td>\n",
              "      <td>y</td>\n",
              "      <td>24h</td>\n",
              "      <td>a_few_moment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27737</td>\n",
              "      <td>I cooked my girlfriend a wonderful breakfast.</td>\n",
              "      <td>food|romance</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>34</td>\n",
              "      <td>USA</td>\n",
              "      <td>m</td>\n",
              "      <td>single</td>\n",
              "      <td>n</td>\n",
              "      <td>24h</td>\n",
              "      <td>half_a_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27754</td>\n",
              "      <td>My Mother gave me a surprise visit at my home.</td>\n",
              "      <td>family</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>26</td>\n",
              "      <td>IND</td>\n",
              "      <td>m</td>\n",
              "      <td>married</td>\n",
              "      <td>n</td>\n",
              "      <td>24h</td>\n",
              "      <td>half_a_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>27772</td>\n",
              "      <td>There was hardly any traffic on my way to work...</td>\n",
              "      <td>career</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>25</td>\n",
              "      <td>USA</td>\n",
              "      <td>m</td>\n",
              "      <td>single</td>\n",
              "      <td>n</td>\n",
              "      <td>24h</td>\n",
              "      <td>at_least_one_hour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>27775</td>\n",
              "      <td>I came to my office at right time.</td>\n",
              "      <td>career</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>22</td>\n",
              "      <td>USA</td>\n",
              "      <td>m</td>\n",
              "      <td>single</td>\n",
              "      <td>n</td>\n",
              "      <td>24h</td>\n",
              "      <td>a_few_moment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>27777</td>\n",
              "      <td>The day I got my degree in industrial engineering</td>\n",
              "      <td>education</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>22</td>\n",
              "      <td>VEN</td>\n",
              "      <td>f</td>\n",
              "      <td>single</td>\n",
              "      <td>n</td>\n",
              "      <td>24h</td>\n",
              "      <td>all_day_im_still_feeling_it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    hmid                                             moment          concepts  \\\n",
              "0  27674  I was happy when my son got 90% marks in his e...  education|family   \n",
              "1  27685          went to movies with my friends it was fun     entertainment   \n",
              "2  27691  A hot kiss with my girl friend last night made...           romance   \n",
              "3  27701  My son woke me up to a fantastic breakfast of ...       family|food   \n",
              "4  27712  My older daughter keeps patting my younger dau...            family   \n",
              "5  27737      I cooked my girlfriend a wonderful breakfast.      food|romance   \n",
              "6  27754     My Mother gave me a surprise visit at my home.            family   \n",
              "7  27772  There was hardly any traffic on my way to work...            career   \n",
              "8  27775                 I came to my office at right time.            career   \n",
              "9  27777  The day I got my degree in industrial engineering         education   \n",
              "\n",
              "  agency social   age country gender  married parenthood reflection  \\\n",
              "0     no    yes  29.0     IND      m  married          y        24h   \n",
              "1    yes    yes  29.0     IND      m   single          y        24h   \n",
              "2    yes    yes  25.0     IND      m  married          y        24h   \n",
              "3     no    yes    79     USA      f  widowed          y        24h   \n",
              "4     no    yes    30     USA      f  married          y        24h   \n",
              "5    yes    yes    34     USA      m   single          n        24h   \n",
              "6     no    yes    26     IND      m  married          n        24h   \n",
              "7    yes     no    25     USA      m   single          n        24h   \n",
              "8    yes     no    22     USA      m   single          n        24h   \n",
              "9    yes     no    22     VEN      f   single          n        24h   \n",
              "\n",
              "                      duration  \n",
              "0                   half_a_day  \n",
              "1                   half_a_day  \n",
              "2            at_least_one_hour  \n",
              "3  all_day_im_still_feeling_it  \n",
              "4                 a_few_moment  \n",
              "5                   half_a_day  \n",
              "6                   half_a_day  \n",
              "7            at_least_one_hour  \n",
              "8                 a_few_moment  \n",
              "9  all_day_im_still_feeling_it  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "0L3XswtLuepv",
        "colab_type": "code",
        "outputId": "fef82869-4d3f-44ad-aa15-13031201c9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(labeled_data.country.unique())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "ZOpgLUS3uez5",
        "colab_type": "code",
        "outputId": "79d0fc4b-5d33-42f7-cf41-6a87ebf8af91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(labeled_data.concepts.unique())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "sH-gvX9p5-NL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, valid = train_test_split(labeled_data, test_size=0.2, random_state=0, stratify=labeled_data['social'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MoOyCFEg6OeG",
        "colab_type": "code",
        "outputId": "fab83fcd-1f46-4da3-c490-6a73d98fea50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train.social.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "yes    4500\n",
              "no     3948\n",
              "Name: social, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "g1XKpMc16TjF",
        "colab_type": "code",
        "outputId": "9be0a2ef-03bb-41f0-82da-899ba61ff2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "valid.social.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "yes    1125\n",
              "no      987\n",
              "Name: social, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "rygV2En4BeOh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = train[['hmid','moment','agency']]\n",
        "valid = valid[['hmid','moment','agency']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JXbGiB5nB7E0",
        "colab_type": "code",
        "outputId": "7d15a2c9-892f-41e9-c153-1a18f0ae1e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "train.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hmid</th>\n",
              "      <th>moment</th>\n",
              "      <th>agency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>32335</td>\n",
              "      <td>I went to an art gallery, which I've never don...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>29833</td>\n",
              "      <td>I learned how to cook a new cake recipe.</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3608</th>\n",
              "      <td>62136</td>\n",
              "      <td>All my friends give me surprise party on my bi...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7568</th>\n",
              "      <td>100495</td>\n",
              "      <td>I ordered three pairs of pants online and when...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1805</th>\n",
              "      <td>44630</td>\n",
              "      <td>I was able to successfully clean a student's c...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2218</th>\n",
              "      <td>48616</td>\n",
              "      <td>I watched one of my favorite shows after a hia...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1318</th>\n",
              "      <td>40100</td>\n",
              "      <td>Gonzaga won its Final Four basketball game.</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2820</th>\n",
              "      <td>54298</td>\n",
              "      <td>I talked on the phone with a good friend of mi...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4891</th>\n",
              "      <td>74912</td>\n",
              "      <td>Going to get a coffee at the bookstore and bro...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4627</th>\n",
              "      <td>72216</td>\n",
              "      <td>Watched a friend's daughter play soccer</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        hmid                                             moment agency\n",
              "484    32335  I went to an art gallery, which I've never don...    yes\n",
              "217    29833           I learned how to cook a new cake recipe.    yes\n",
              "3608   62136  All my friends give me surprise party on my bi...     no\n",
              "7568  100495  I ordered three pairs of pants online and when...    yes\n",
              "1805   44630  I was able to successfully clean a student's c...    yes\n",
              "2218   48616  I watched one of my favorite shows after a hia...    yes\n",
              "1318   40100        Gonzaga won its Final Four basketball game.     no\n",
              "2820   54298  I talked on the phone with a good friend of mi...    yes\n",
              "4891   74912  Going to get a coffee at the bookstore and bro...    yes\n",
              "4627   72216            Watched a friend's daughter play soccer    yes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "l_4L-ShF3iOP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train.to_csv('train_data.csv',index=False)\n",
        "valid.to_csv('valid_data.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5sACbfI17ZT",
        "colab_type": "code",
        "outputId": "dacf5e47-fc67-4a4b-e1e3-e2db28a1df82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "from skimage import transform\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter,OrderedDict\n",
        "from keras.utils.vis_utils import *\n",
        "import random\n",
        "import math"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NT9hjh34gGr9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from torchtext import vocab\n",
        "# specify the path to the localy saved vectors\n",
        "vec = vocab.GloVe(name='840B', dim=300)\n",
        "# vec = vocab.GloVe(name='6B', dim=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "28EUVijcR5bD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "import spacy\n",
        "import re\n",
        "from torchtext import data\n",
        "\n",
        "# tokenizer function using spacy\n",
        "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
        "def tokenizer(s): \n",
        "    return [w.text.lower() for w in nlp(tweet_clean(s))]\n",
        "\n",
        "def tweet_clean(text):\n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric character\n",
        "    text = re.sub(r'https?:/\\/\\S+', ' ', text) # remove links\n",
        "    return text.strip()\n",
        "\n",
        "def tokenizer(s): \n",
        "    return [w.text.lower() for w in nlp(tweet_clean(s))]\n",
        "\n",
        "# define the columns that we want to process and how to process\n",
        "TEXT = data.Field(sequential=True, \n",
        "                 tokenize=tokenizer, \n",
        "                 include_lengths=True, \n",
        "                 use_vocab=True)\n",
        "LABEL = data.Field(sequential=False, \n",
        "                   use_vocab=True,\n",
        "                   pad_token=None, \n",
        "                   unk_token=None)\n",
        "\n",
        "train_val_fields = [\n",
        "    (\"hmid\", None),\n",
        "    ('moment', TEXT), # process it as text\n",
        "    ('agency', LABEL) # process it as label\n",
        "]\n",
        "\n",
        "trainds, valds = data.TabularDataset.splits(path='', \n",
        "                                            format='csv', \n",
        "                                            train='train_data.csv', \n",
        "                                            validation='valid_data.csv', \n",
        "                                            fields=train_val_fields, \n",
        "                                            skip_header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73zEBx4_lQwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the vocabulary using train and validation dataset and assign the vectors\n",
        "TEXT.build_vocab(trainds,valds, max_size=100000, vectors=vec)\n",
        "# build vocab for labels\n",
        "LABEL.build_vocab(trainds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHmzIO3_85sI",
        "colab_type": "code",
        "outputId": "c1513ba1-2b48-4d2d-9e8a-a324147f40c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.vectors)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9afOJyTKk8Rv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds), # specify train and validation Tabulardataset\n",
        "                                            batch_sizes=(64,len(valid)),  # batch size of train and validation\n",
        "                                            sort_key=lambda x: len(x.moment), # on what attribute the text should be sorted\n",
        "                                            device=None, # -1 mean cpu and 0 or None mean gpu\n",
        "                                            sort_within_batch=True, \n",
        "                                            repeat=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N6ZGgIxc39A2",
        "colab_type": "code",
        "outputId": "2252980a-43d4-4cab-ce34-c1bb0c4c77c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(traindl), len(valdl))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "132 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t9mIWH8v9Tcr",
        "colab_type": "code",
        "outputId": "24157e10-6930-458f-921d-86b690c57f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "traindl"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.iterator.BucketIterator at 0x7f0a8e870438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "X4tZudVU3_OG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(traindl)) # BucketIterator return a batch object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNKXAgZB4A4X",
        "colab_type": "code",
        "outputId": "cac4e325-e23a-4736-808e-5579401f8bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(batch.agency) # labels of the batch"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HfWglGms4CHK",
        "colab_type": "code",
        "outputId": "ca898ba5-a384-4f57-a31a-b10f0329c7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "print(batch.moment) "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[   2,    2,    2,    2,    2,   30,    2,    2,    2,    2,    2,    2,\n",
            "          291,    2,  100,    2,    2,    2,    2,    3,    2,    2,    2,    2,\n",
            "           31,  330,   96,    3,    2,  330,    3,  129,    2,   22,  392,    2,\n",
            "          469,   37,   17,  492,    3,   18,   96,    2,  165,  330,  165,    2,\n",
            "            3,  223,    2,    4,    3,   96,    2,  129,   18,  351, 5762,    2,\n",
            "          834, 5171,  636,  230],\n",
            "        [  18,  100,   18,  267,  125,   52,  501,   18,  100,   18,  898,   18,\n",
            "            4,   18,    4,  402,   18,   18,   18,   34,   18,  154,   18,   85,\n",
            "           87,   11,  120,  123,   18,   11,   34,    3,  154,   36,    3,   22,\n",
            "            5,   85,    7,  461,  178,  463,    4,   17,  152,    5,  152,   85,\n",
            "          836,    3,   18, 5928,   34,    3,   85, 1809,    5,   35,  348,   17,\n",
            "          784,  124,    9,  410],\n",
            "        [   5,   36,    5,    3, 1325,    4,    5,    5,   41,    5,  198,    5,\n",
            "          601,    5,   72,    5,    5,    5,    5,  365,    5,   36,    7,  211,\n",
            "          149,   40,   24,   70, 1423,   40,   70,  211, 3538,  850,  836,   47,\n",
            "          303,  863,  593,  139,   70,  104,  307,  908,  232,   40,  232,  211,\n",
            "           70,  829,  115,  651,   70, 3604, 7181, 5617,  104,  365,  504,  534,\n",
            "          240, 4309,  243, 1516],\n",
            "        [ 104, 1556,  104,  108,   99,  111,  303,  104,  214,  386,  173,  130,\n",
            "          105,  130,  568,  136,  104,  130,  812,  127,  130, 2462,  115,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1]]), tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XQkVolv04Dfs",
        "colab_type": "code",
        "outputId": "3fec3abe-4047-446f-cad6-87175a804b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(batch.dataset.fields)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hmid': None, 'moment': <torchtext.data.field.Field object at 0x7f0a8716db38>, 'agency': <torchtext.data.field.Field object at 0x7f0b0f2360f0>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EahfEJ1rAGx4",
        "colab_type": "code",
        "outputId": "85b240eb-4007-4544-f61d-efcd8827a2d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(x,lengths) = batch.moment\n",
        "x.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "peOOj2MEANPe",
        "colab_type": "code",
        "outputId": "3bd99caa-2fbf-4090-8fc8-dba973703e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "batch.agency.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "ssMm5Wp54E2D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BatchGenerator:\n",
        "    def __init__(self, dl, x_field, y_field):\n",
        "        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            X = getattr(batch, self.x_field)\n",
        "            y = getattr(batch, self.y_field)\n",
        "            yield (X,y)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJ1TfTlA4F7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_batch_it = BatchGenerator(traindl, 'moment', 'agency')\n",
        "valid_batch_it = BatchGenerator(valdl, 'moment', 'agency')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6LKOxYP7kHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        " \n",
        "class AttentionLSTM(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_lstm_layers,emb_dim, dropout_p):\n",
        "        super(AttentionLSTM,self).__init__() # don't forget to call this!\n",
        "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
        "        self.embedding.weight = nn.Parameter(TEXT.vocab.vectors, requires_grad=False)\n",
        "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=n_lstm_layers)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1=nn.Linear(hidden_dim,64)\n",
        "        self.predictor=nn.Linear(64,1)\n",
        " \n",
        "    def attention_net(self, lstm_output, final_state):\n",
        "        hidden = final_state.permute(1,2,0)\n",
        "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)\n",
        "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
        "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
        "        return new_hidden_state\n",
        "  \n",
        "    def forward(self, seq):\n",
        "        output, (final_hidden_state, final_cell_state) = self.encoder(self.embedding(seq))\n",
        "        output = output.permute(1, 0, 2) # output.size() = (batch_size, num_seq, hidden_size)\n",
        "        attn_output = self.attention_net(output, final_hidden_state)\n",
        "        attn_output= self.dropout(attn_output)\n",
        "        fc_output= self.fc1(attn_output)\n",
        "        fc_output= self.dropout(fc_output)\n",
        "        preds=self.predictor(fc_output)\n",
        "        return torch.sigmoid(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PObJ6utqAtNF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed_size = 300\n",
        "nh = 128\n",
        "drop=0.75\n",
        "n_lstm_layers=1\n",
        "model = AttentionLSTM(nh,n_lstm_layers,embed_size,drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKn5fzsc_DQO",
        "colab_type": "code",
        "outputId": "28af56cd-a43b-411a-fa80-b2cee6549f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_func = nn.BCELoss()\n",
        "epochs = 20\n",
        "batch_size = 64 \n",
        "scheduler = StepLR(opt, step_size=5, gamma=0.1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    iterations=0\n",
        "    scheduler.step()\n",
        "    model.train() # turn on training mode\n",
        "    for x,y in tqdm(train_batch_it,disable=True): # thanks to our wrapper, we can intuitively iterate over our data!\n",
        "        iterations=iterations+1\n",
        "        opt.zero_grad()\n",
        "        (x,lengths)=x\n",
        "        predicted = model(x)\n",
        "        predicted=predicted.view(-1)\n",
        "        loss = loss_func(predicted,y.float())\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "    epoch_loss = running_loss / len(trainds)\n",
        " \n",
        "    # calculate the validation loss for this epoch\n",
        "    val_loss = 0.0\n",
        "    list_scores=[]\n",
        "    model.eval() # turn on evaluation mode\n",
        "    for x,y in tqdm(valid_batch_it,disable=True):\n",
        "        (x,lengths)=x\n",
        "        preds = model(x)\n",
        "        loss = loss_func(preds,y.float())\n",
        "        val_loss += loss.item() * x.size(0)\n",
        "        preds = [int(x>0.5) for x in preds]\n",
        "        temp=accuracy_score(preds,y)\n",
        "    \n",
        "    val_loss /= len(valds)\n",
        "    state = {\n",
        "    'epoch': epoch,\n",
        "    'state_dict': model.state_dict(),\n",
        "    'optimizer': opt.state_dict(),\n",
        "    }\n",
        "    torch.save(state, 'mytraining1'+str(epoch)+'.pt')\n",
        "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}'.format(epoch, epoch_loss, val_loss,temp))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([2112])) that is different to the input size (torch.Size([2112, 1])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training Loss: 0.1217, Validation Loss: 0.0168, Validation Accuracy: 0.7467\n",
            "Epoch: 2, Training Loss: 0.0964, Validation Loss: 0.0143, Validation Accuracy: 0.7841\n",
            "Epoch: 3, Training Loss: 0.0873, Validation Loss: 0.0142, Validation Accuracy: 0.7457\n",
            "Epoch: 4, Training Loss: 0.0821, Validation Loss: 0.0148, Validation Accuracy: 0.8438\n",
            "Epoch: 5, Training Loss: 0.0794, Validation Loss: 0.0119, Validation Accuracy: 0.8561\n",
            "Epoch: 6, Training Loss: 0.0719, Validation Loss: 0.0113, Validation Accuracy: 0.8546\n",
            "Epoch: 7, Training Loss: 0.0721, Validation Loss: 0.0116, Validation Accuracy: 0.8523\n",
            "Epoch: 8, Training Loss: 0.0689, Validation Loss: 0.0113, Validation Accuracy: 0.8494\n",
            "Epoch: 9, Training Loss: 0.0691, Validation Loss: 0.0115, Validation Accuracy: 0.8556\n",
            "Epoch: 10, Training Loss: 0.0690, Validation Loss: 0.0113, Validation Accuracy: 0.8537\n",
            "Epoch: 11, Training Loss: 0.0677, Validation Loss: 0.0113, Validation Accuracy: 0.8551\n",
            "Epoch: 12, Training Loss: 0.0675, Validation Loss: 0.0113, Validation Accuracy: 0.8551\n",
            "Epoch: 13, Training Loss: 0.0679, Validation Loss: 0.0114, Validation Accuracy: 0.8542\n",
            "Epoch: 14, Training Loss: 0.0673, Validation Loss: 0.0114, Validation Accuracy: 0.8527\n",
            "Epoch: 15, Training Loss: 0.0679, Validation Loss: 0.0113, Validation Accuracy: 0.8546\n",
            "Epoch: 16, Training Loss: 0.0670, Validation Loss: 0.0113, Validation Accuracy: 0.8546\n",
            "Epoch: 17, Training Loss: 0.0671, Validation Loss: 0.0113, Validation Accuracy: 0.8551\n",
            "Epoch: 18, Training Loss: 0.0672, Validation Loss: 0.0113, Validation Accuracy: 0.8551\n",
            "Epoch: 19, Training Loss: 0.0682, Validation Loss: 0.0113, Validation Accuracy: 0.8551\n",
            "Epoch: 20, Training Loss: 0.0674, Validation Loss: 0.0113, Validation Accuracy: 0.8546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RPzYXTZHFFhw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index = 5\n",
        "from google.colab import files\n",
        "files.download('mytraining'+str(index)+'.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}